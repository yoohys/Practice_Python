{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch10-3.RNN: Sequence2Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seq2Seq 번역하기(구글 번역)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (예) word -> 번역: 단어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#소문자 a~z까지 배열변수에 넣기\n",
    "#S:decoder Start,  E: decoder End, P:심볼\n",
    "char_arr=[c for c in 'SEPabcdefghijklmnopqrstuvwxyz단어나무놀이소녀키스사랑']\n",
    "num_dic={n:i for i,n in enumerate(char_arr)}\n",
    "dic_len=len(num_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_data = [['word', '단어'], ['wood', '나무'],\n",
    "            ['game', '놀이'], ['girl', '소녀'],\n",
    "            ['kiss', '키스'], ['love', '사랑']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch(seq_data):\n",
    "    input_batch=[]\n",
    "    output_batch=[]\n",
    "    target_batch=[]\n",
    "    \n",
    "    for seq in seq_data:\n",
    "        input=[num_dic[n] for n in seq[0]]\n",
    "        output=[num_dic[n] for n in ('S'+seq[1])]\n",
    "        target=[num_dic[n] for n in (seq[1]+'E')]\n",
    "        \n",
    "        input_batch.append(np.eye(dic_len)[input])\n",
    "        output_batch.append(np.eye(dic_len)[output])\n",
    "        target_batch.append(target)\n",
    "        \n",
    "    return input_batch, output_batch, target_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.01 #최적화함수에서 사용할 학습률\n",
    "total_epoch=100#전체 데이터를 학습할 총 횟수\n",
    "n_hidden=128 #hidden layer의 뉴런 갯수\n",
    "n_input=n_class=dic_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_input=tf.placeholder(tf.float32,[None,None, n_input]) \n",
    "dec_input=tf.placeholder(tf.float32,[None,None,n_input]) \n",
    "targets=tf.placeholder(tf.int64,[None,None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-52b1601d878a>:2: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-7-52b1601d878a>:5: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\rnn_cell_impl.py:456: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\rnn_cell_impl.py:460: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('encode'):\n",
    "    enc_cell = tf.nn.rnn_cell.BasicRNNCell(n_hidden)\n",
    "    enc_cell = tf.nn.rnn_cell.DropoutWrapper(enc_cell, output_keep_prob=0.5)\n",
    "\n",
    "    outputs, enc_states = tf.nn.dynamic_rnn(enc_cell, enc_input, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('decode'):\n",
    "    dec_cell = tf.nn.rnn_cell.BasicRNNCell(n_hidden)\n",
    "    dec_cell = tf.nn.rnn_cell.DropoutWrapper(dec_cell, output_keep_prob=0.5)\n",
    "\n",
    "    outputs, dec_states = tf.nn.dynamic_rnn(dec_cell, dec_input, initial_state=enc_states, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-92f931a32b6b>:1: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\layers\\core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n"
     ]
    }
   ],
   "source": [
    "model = tf.layers.dense(outputs, n_class, activation=None)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=model, labels=targets))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0001 Cost=  3.755042\n",
      "Epoch:  0002 Cost=  2.514495\n",
      "Epoch:  0003 Cost=  1.681527\n",
      "Epoch:  0004 Cost=  1.132293\n",
      "Epoch:  0005 Cost=  0.635849\n",
      "Epoch:  0006 Cost=  0.470242\n",
      "Epoch:  0007 Cost=  0.257953\n",
      "Epoch:  0008 Cost=  0.271767\n",
      "Epoch:  0009 Cost=  0.202466\n",
      "Epoch:  0010 Cost=  0.233496\n",
      "Epoch:  0011 Cost=  0.070391\n",
      "Epoch:  0012 Cost=  0.084783\n",
      "Epoch:  0013 Cost=  0.079297\n",
      "Epoch:  0014 Cost=  0.032873\n",
      "Epoch:  0015 Cost=  0.037073\n",
      "Epoch:  0016 Cost=  0.101700\n",
      "Epoch:  0017 Cost=  0.021992\n",
      "Epoch:  0018 Cost=  0.024138\n",
      "Epoch:  0019 Cost=  0.071132\n",
      "Epoch:  0020 Cost=  0.020519\n",
      "Epoch:  0021 Cost=  0.005445\n",
      "Epoch:  0022 Cost=  0.009812\n",
      "Epoch:  0023 Cost=  0.006248\n",
      "Epoch:  0024 Cost=  0.012702\n",
      "Epoch:  0025 Cost=  0.002832\n",
      "Epoch:  0026 Cost=  0.002740\n",
      "Epoch:  0027 Cost=  0.004442\n",
      "Epoch:  0028 Cost=  0.002861\n",
      "Epoch:  0029 Cost=  0.002760\n",
      "Epoch:  0030 Cost=  0.006013\n",
      "Epoch:  0031 Cost=  0.004151\n",
      "Epoch:  0032 Cost=  0.004477\n",
      "Epoch:  0033 Cost=  0.004534\n",
      "Epoch:  0034 Cost=  0.005781\n",
      "Epoch:  0035 Cost=  0.002518\n",
      "Epoch:  0036 Cost=  0.002254\n",
      "Epoch:  0037 Cost=  0.001628\n",
      "Epoch:  0038 Cost=  0.002440\n",
      "Epoch:  0039 Cost=  0.001306\n",
      "Epoch:  0040 Cost=  0.004074\n",
      "Epoch:  0041 Cost=  0.000994\n",
      "Epoch:  0042 Cost=  0.006833\n",
      "Epoch:  0043 Cost=  0.013435\n",
      "Epoch:  0044 Cost=  0.002012\n",
      "Epoch:  0045 Cost=  0.000834\n",
      "Epoch:  0046 Cost=  0.004075\n",
      "Epoch:  0047 Cost=  0.001092\n",
      "Epoch:  0048 Cost=  0.002254\n",
      "Epoch:  0049 Cost=  0.002443\n",
      "Epoch:  0050 Cost=  0.001443\n",
      "Epoch:  0051 Cost=  0.000805\n",
      "Epoch:  0052 Cost=  0.005337\n",
      "Epoch:  0053 Cost=  0.000927\n",
      "Epoch:  0054 Cost=  0.000947\n",
      "Epoch:  0055 Cost=  0.001817\n",
      "Epoch:  0056 Cost=  0.000777\n",
      "Epoch:  0057 Cost=  0.002241\n",
      "Epoch:  0058 Cost=  0.000647\n",
      "Epoch:  0059 Cost=  0.000509\n",
      "Epoch:  0060 Cost=  0.003007\n",
      "Epoch:  0061 Cost=  0.000377\n",
      "Epoch:  0062 Cost=  0.001052\n",
      "Epoch:  0063 Cost=  0.000390\n",
      "Epoch:  0064 Cost=  0.000188\n",
      "Epoch:  0065 Cost=  0.000429\n",
      "Epoch:  0066 Cost=  0.000352\n",
      "Epoch:  0067 Cost=  0.005231\n",
      "Epoch:  0068 Cost=  0.001702\n",
      "Epoch:  0069 Cost=  0.000510\n",
      "Epoch:  0070 Cost=  0.000576\n",
      "Epoch:  0071 Cost=  0.000418\n",
      "Epoch:  0072 Cost=  0.001388\n",
      "Epoch:  0073 Cost=  0.000506\n",
      "Epoch:  0074 Cost=  0.000486\n",
      "Epoch:  0075 Cost=  0.000340\n",
      "Epoch:  0076 Cost=  0.000404\n",
      "Epoch:  0077 Cost=  0.001636\n",
      "Epoch:  0078 Cost=  0.000673\n",
      "Epoch:  0079 Cost=  0.000287\n",
      "Epoch:  0080 Cost=  0.000269\n",
      "Epoch:  0081 Cost=  0.001134\n",
      "Epoch:  0082 Cost=  0.001010\n",
      "Epoch:  0083 Cost=  0.000566\n",
      "Epoch:  0084 Cost=  0.000417\n",
      "Epoch:  0085 Cost=  0.000521\n",
      "Epoch:  0086 Cost=  0.000516\n",
      "Epoch:  0087 Cost=  0.000581\n",
      "Epoch:  0088 Cost=  0.001018\n",
      "Epoch:  0089 Cost=  0.001709\n",
      "Epoch:  0090 Cost=  0.000467\n",
      "Epoch:  0091 Cost=  0.000326\n",
      "Epoch:  0092 Cost=  0.000433\n",
      "Epoch:  0093 Cost=  0.000620\n",
      "Epoch:  0094 Cost=  0.000323\n",
      "Epoch:  0095 Cost=  0.000252\n",
      "Epoch:  0096 Cost=  0.000712\n",
      "Epoch:  0097 Cost=  0.000284\n",
      "Epoch:  0098 Cost=  0.000554\n",
      "Epoch:  0099 Cost=  0.001439\n",
      "Epoch:  0100 Cost=  0.000453\n",
      "최적화 완료!\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "input_batch, output_batch, target_batch = make_batch(seq_data)\n",
    "\n",
    "for epoch in range(total_epoch):\n",
    "\n",
    "    _, loss = sess.run([optimizer, cost], feed_dict={enc_input: input_batch,\n",
    "                                                     dec_input: output_batch,\n",
    "                                                     targets: target_batch})\n",
    "\n",
    "    print('Epoch: ', '%04d' % (epoch + 1),\n",
    "          'Cost= ', '{:.6f}'.format(loss))\n",
    "\n",
    "print('최적화 완료!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 번역 테스트 ===\n",
      "word -> 단어\n",
      "wodr -> 나무\n",
      "love -> 사랑\n",
      "loev -> 사랑\n",
      "abcd -> 키스\n"
     ]
    }
   ],
   "source": [
    "def translate(word):\n",
    "\n",
    "    seq_data = [word, 'P' * len(word)]\n",
    "\n",
    "    input_batch, output_batch, target_batch = make_batch([seq_data])\n",
    "\n",
    "    # 1argmax(model, 2): 3차원\n",
    "    prediction = tf.argmax(model, 2)\n",
    "\n",
    "    result = sess.run(prediction, feed_dict={enc_input: input_batch,\n",
    "                                             dec_input: output_batch,\n",
    "                                             targets: target_batch})\n",
    "\n",
    "    # 10.3.10\n",
    "    decoded = [char_arr[i] for i in result[0]]\n",
    "\n",
    "    end = decoded.index('E')\n",
    "    translated = ''.join(decoded[:end])\n",
    "\n",
    "    return translated\n",
    "\n",
    "# 10.3.11\n",
    "print('\\n=== 번역 테스트 ===')\n",
    "\n",
    "print('word ->', translate('word'))\n",
    "print('wodr ->', translate('wodr')) ##### 알수없는 값\n",
    "print('love ->', translate('love'))\n",
    "print('loev ->', translate('loev'))\n",
    "print('abcd ->', translate('abcd')) #### 알수없는 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
